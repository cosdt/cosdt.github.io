{"posts":[{"title":"EulerPublisher: 一键发布openEuler镜像背后的技术","text":"作者：@wjunLu 1. EulerPublisher架构eulerpublisher作为一款openEuler“一键式”发布工具，提供openEuler容器镜像、云镜像、WSL等镜像定制、发布和测试的能力。本项目主要使用python语言实现，并且以CLI的方式提供给用户使用。 eulerpublisher按照使用场景，分为容器镜像(container)、云镜像(cloudimg)、WSL(wsl)这几个模块，而每个模块又按照子场景划分不同的子功能模块，每个子场景功能模块具备prepare、build、publish、check等能力，因而形成一种按照主场景、子场景、以及对应动作构成的分层软件架构，如图所示： 以下围绕eulerpublisher cli的使用方式，来理解eulerpublisher的软件架构，cli通用形式如下： 1eulerpublisher &lt;Command1&gt; &lt;Command2&gt; &lt;Command3&gt; &lt;Options&gt; 详细说明如下： Command1Command1为主场景命令，使用时必填，取值有container、cloudimg、wsl等 Command2 Command2确定子场景，使用时可选，具体情况如下： Command1 == container场景，使用Docker完成镜像构建等一系列动作，暂无其他子场景，无 Command2； Command1 ==cloudimg场景，会针对不同云厂商有着不同的镜像定制及发布要求，因此Command 2必选，取值有aws、azure、hwcloud等。 Command3Command3是Command 1～2 组合场景下的“动作”，可选prepare、build、push、publish、check等，具体Command 1~3的可选组合请使用eulerpublisher --help逐级查看 OptionsOptions是被执行命令的一组参数，每个不同的Command 1~3组合会有不同的参数选择，使用eulerpublisher --help查看。 示例如下： container场景 12# 容器镜像发布eulerpublisher container publish --repo openeuler/openeuler --version 22.03-LTS-SP1 --registry registry-1.docker.io --dockerfile /Path/To/Dockerfile 上述效果是向dockerhub(https://hub.docker.com)的openeuler/openeuler仓库发布由Dockerfile定制的tag为22.03-LTS-SP1的支持arm64、amd64多平台的openeuler容器镜像。 cloudimg场景 12# AMI镜像构建eulerpublisher cloudimg aws build --version 22.03-LTS-SP1 --arch aarch64 --bucket openeuler --region ap-southeast-2 此命令将在AWS的ap-southeast-2区的AMI列表生成一个22.03-LTS-SP1版本的aarch64架构的openEuler镜像，其制作的原始镜像来源于openeuler桶中。 2. EulerPublisher容器镜像构建原理背景eulerpublisher基于Docker CLI和Dockerfile实现定制Docker容器镜像的功能。在介绍eulerpublisher实现容器镜像构建的原理之前，有必要先梳理一下有关的背景知识： 1). 容器镜像容器镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的配置参数。关于容器和容器镜像的关系，可以类比为程序设计中的类和实例，容器镜像是静态的类定义，容器是镜像运行时的实例。 2). Docker镜像分层Docker镜像是由多个文件系统叠加而成。最底层是一个引导文件系统，即bootfs，第二层是root文件系统 rootfs，它位于bootfs之上，其他的文件系统在rootfs之上。 在Docker镜像中，所有的文件系统是只读的，这也体现了Docker镜像的静态属性。当Docker启动一个容器时，会加载这些只读层并在这些只读层的上面增加一个读写层，该读写层一般也被称为容器层。这时如果修改正在运行的容器中已有的文件，那么这个文件将会从只读层复制到读写层。该文件的只读版本还在，只是被上面读写层的该文件的副本隐藏。当删除docker，或者重新启动时，之前的更改将会消失。 3). DockerfileDockerfile是构建Docker镜像的“生产手册”，决定着Docker镜像的内容，以下是Dockerfile指令 Dockerfile 指令 说明 FROM 指定基础镜像，用于后续的指令构建。 MAINTAINER 指定Dockerfile的作者/维护者。（已弃用，推荐使用LABEL指令） LABEL 添加镜像的元数据，使用键值对的形式。 RUN 在构建过程中在镜像中执行命令。 CMD 指定容器创建时的默认命令。（可以被覆盖） ENTRYPOINT 设置容器创建时的主要命令。（不可被覆盖） EXPOSE 声明容器运行时监听的特定网络端口。 ENV 在容器内部设置环境变量。 ADD 将文件、目录或远程URL复制到镜像中。 COPY 将文件或目录复制到镜像中。 VOLUME 为容器创建挂载点或声明卷。 WORKDIR 设置后续指令的工作目录。 USER 指定后续指令的用户上下文。 ARG 定义在构建过程中传递给构建器的变量，可使用 “docker build” 命令设置。 ONBUILD 当该镜像被用作另一个构建过程的基础时，添加触发器。 STOPSIGNAL 设置发送给容器以退出的系统调用信号。 HEALTHCHECK 定义周期性检查容器健康状态的命令。 SHELL 覆盖Docker中默认的shell，用于RUN、CMD和ENTRYPOINT指令。 示例 12345678# eulerpublisher的默认DockerfileFROM scratchARG TARGETARCHADD openEuler-docker-rootfs.$TARGETARCH.tar.xz /RUN ln -sf /usr/share/zoneinfo/UTC /etc/localtime &amp;&amp; \\ sed -i &quot;s/TMOUT=300/TMOUT=0/g&quot; /etc/bashrcCMD [&quot;bash&quot;] 解释 FROM scratch指定构建的Docker镜像的基础镜像是scratch，即一个空白镜像，没有预装任何软件包或依赖项。 ARG TARGETARCH声明一个构建变量TARGETARCH，在构建过程中会提供该变量的值。 ADD openEuler-docker-rootfs.$TARGETARCH.tar.xz /将根文件系统的压缩包（openEuler-docker-rootfs.$TARGETARCH.tar.xz）添加到Docker镜像的根目录（/）中。 RUN ln -sf /usr/share/zoneinfo/UTC /etc/localtime &amp;&amp; \\ …设置系统时区为UTC、设置TMOUT=0、更新yum并清理缓存。 CMD [“bash”]指定了在Docker镜像运行容器时要执行的默认命令为bash，即启动一个交互式的Bash shell会话。 需要注意的是，通过Dockerfile构建Docker镜像时，Dockerfile中的每一个写指令执行后都将会在最终镜像增加一层。因此，为了减少镜像的分层（又称为镜像裁剪），编写Dockerfile时尽可能一行命令执行多个写操作。如上述Dockerfile中RUN ln -sf /usr/share/zoneinfo/UTC /etc/localtime &amp;&amp; \\ sed -i &quot;s/TMOUT=300/TMOUT=0/g&quot; /etc/bashrc使用一行命令执行2个操作也是出于此目的。 使用eulerpublisher默认Dockerfile构建的镜像分层(size不为0的)如下 12345IMAGE CREATED CREATED BY SIZE COMMENTd9bff1b2db49 7 months ago CMD [&quot;bash&quot;] 0B buildkit.dockerfile.v0&lt;missing&gt; 7 months ago RUN |1 TARGETARCH=amd64 /bin/sh -c ln -sf /u… 168kB buildkit.dockerfile.v0&lt;missing&gt; 7 months ago ADD openEuler-docker-rootfs.amd64.tar.xz / #… 191MB buildkit.dockerfile.v0&lt;missing&gt; 7 months ago ARG TARGETARCH 0B buildkit.dockerfile.v0 4). docker buildx buildeulerpublisher使用docker buildx build命令构建多架构（linux/arm64, linux/amd64）的openEuler镜像，核心命令示例如下： 1docker buildx build -t openeuler/openeuler:22.03-LTS-SP1 --platform linux/arm64,linux/amd64 --push . 该命令使用默认Dockerfile（见上文）构建openEuler镜像，由于多平台镜像构建结果无法在本地缓存，只能使用--push保存在openeuler/openeuler仓库中。 Eulerpublisher容器镜像构建有了上述基础以后，eulerpublisher构建容器镜像的思路就很容易理解。 1）按照Dockerfile的内容，eulerpublisher制作镜像前需要先获取openEuler-docker-rootfs.$TARGETARCH.tar.xz。该步骤由prepare功能实现，执行命令示例如下 1eulerpublisher container prepare --version 22.03-LTS-SP1 该命令从http://repo.openeuler.org/下载aarch64和x86_64的原始镜像，将主要文件重新压缩后得到openEuler-docker-rootfs.amd64.tar.xz和openEuler-docker-rootfs.arm64.tar.xz两个文件。 2）获取openEuler-docker-rootfs.$TARGETARCH.tar.xz之后，使用push功能构建并保存镜像，命令示例如下 1eulerpublisher container push --repo openeuler/openeuler --version 22.03-LTS-SP1 --registry registry-1.docker.io --dockerfile /Path/To/Dockerfile 该命令的核心步骤就是执行docker buildx build，构建的镜像将会保存在dockerhub的openeuler/openeuler仓库，tag为22.03-LTS-SP1。 3. EulerPublisher云镜像构建原理这部分描述eulerpublisher构建符合云商marketplace发布要求的云镜像的基本原理，按厂商不同分开说明 AWS镜像发布要求AWS Marketplace对发布的镜像规格存在一定约束： Virtual size最小为8GB ssh禁用password登录 ssh禁用root用户登录 禁止set_hostname 禁止生成用户默认密码 为了满足上述约束，eulerpublisher提供如下两个脚本 aws_resize.sh 用于改变镜像大小和格式，并配置arm版本的ena.ko使能 aws_install.sh 用于修改镜像默认配置，并安装预置软件包 AMI构建原理eulerpublisher构建AMI分为两个阶段：1. prepare阶段 12# prepare命令eulerpublisher -v {VERSION} -a {ARCH} -b {BUCKET} (a). 从repo.openeuler.org下载版本为VERSION、架构为ARCH的原始qcow2镜像 (b). (arm镜像)配置ena.ko使能 (c). 通过aws_resize.sh脚本resize该qcow2镜像并转换格式为RAW (d). 通过AWS CLI将处理后的RAW镜像upload到AWS S3存储桶BUCKET中以上操作均在本地完成，得到制作AMI的基础镜像。 2. build阶段 12# build命令eulerpublisher -v {VERSION} -a {ARCH} -b {BUCKET} -r {REGION} -p {RPMLIST} eulerpublisher通过packer在prepare的结果之上实现对AMI的定制，具体处理如下 (e). 使用packer启动REGION中存储桶BUCKET的 “基础云镜像” 虚拟机实例 (f). 在虚拟机中安装基础软件包，删除 root 密码、禁用password登录等。 (g). 最终制作的云镜像命名为openEuler-{VERSION}-{ARCH}-{DATETIME}-hvm上述过程中需要准备好packer配置文件，packer配置文件的内容会由eulerpublisher进行填充。此外，若用户需要在最终镜像内预置软件包，需要提供rpmlist 123456789101112131415161718192021222324252627# x86镜像构建的packer配置文件{ &quot;builders&quot;: [ { &quot;type&quot;: &quot;amazon-ebs&quot;, &quot;name&quot;: &quot;amazon-ebs-hvm-amd64&quot;, &quot;region&quot;: &quot;ap-southeast-2&quot;, &quot;ami_regions&quot;: [ &quot;ap-southeast-2&quot; ], &quot;source_ami&quot;: &quot;ami-0df315962e87a4cae&quot;, &quot;instance_type&quot;: &quot;t3a.micro&quot;, &quot;ssh_username&quot;: &quot;root&quot;, &quot;ssh_password&quot;: &quot;openEuler12#$&quot;, &quot;ami_name&quot;: &quot;openEuler-22.03-LTS-SP1-x86_64-20230719-hvm&quot;, &quot;ena_support&quot;: &quot;true&quot; } ], &quot;provisioners&quot;: [ { &quot;type&quot;: &quot;shell&quot;, &quot;environment_vars&quot;: [ ], &quot;script&quot;: &quot;aws_install.sh&quot; } ]} 12345678# rpmlist示例cloud-initwgettartelnetunzipcurl...","link":"/2023/07/20/EulerPublisher-%E4%B8%80%E9%94%AE%E5%8F%91%E5%B8%83openEuler%E9%95%9C%E5%83%8F%E8%83%8C%E5%90%8E%E7%9A%84%E6%8A%80%E6%9C%AF/"},{"title":"ONNXRuntime入门 - 如何编译ONNXRuntime?","text":"作者：@zhangsibo1129 本文介绍如何从0到1完成ONNXRuntime项目的编译。 华为云 ECS 服务器配置如下 123实例类型：AI加速型ai1s规格名称：ai1s.large.4操作系统：Ubuntu 18.04 1.安装驱动若驱动版本太老，卸载旧驱动 12345678cd /usr/local/Ascend/opp/aicpu/script./uninstall.shcd /usr/local/Ascend/ascend-toolkit/latest/toolkit/script./uninstall.shcd /usr/local/Ascend/driver/script./uninstall.sh 安装最新驱动，NPU 型号 Atlas 300I 推理卡（型号：3010） 12345678# 添加执行权限chmod u+x A300-3010-npu-driver_6.0.0_linux-x86_64.run# 安装驱动./A300-3010-npu-driver_6.0.0_linux-x86_64.run --full# 若能正常显示两块 Ascend 310，则安装成功npu-smi info 2.安装开发套件安装 Anaconda 1234567891011121314151617# 下载安装包wget https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh# 增加可执行权限chmod u+x Anaconda3-2023.03-1-Linux-x86_64.sh# 执行安装，选择执行 conda init./Anaconda3-2023.03-1-Linux-x86_64.sh# 更新 condaconda update -n base -c defaults conda# 重新打开终端进入base环境，并创建虚拟环境conda create -n onnxruntime python=3.8# 激活环境conda activate onnxruntime 安装依赖 12345# 安装依赖依赖软件apt-get install -y gcc g++ make cmake zlib1g zlib1g-dev openssl libsqlite3-dev libssl-dev libffi-dev unzip pciutils net-tools libblas-dev gfortran libblas3 libopenblas-dev# 安装 python 库conda install attrs numpy decorator sympy cffi pyyaml pathlib2 psutil protobuf scipy requests 安装开发套件，在官网选择合适版本 12345678# 下载安装包wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Florence-ASL/Florence-ASL%20V100R001C30SPC702/Ascend-cann-toolkit_6.3.RC2.alpha002_linux-x86_64.run# 修改权限chmod u+x Ascend-cann-toolkit_6.3.RC2.alpha002_linux-x86_64.run# 安装./Ascend-cann-toolkit_6.3.RC2.alpha002_linux-x86_64.run --install 3.项目编译安装 cmake-3.26 或更高版本 1python3 -m pip install cmake 升级 gcc 和 g++ 版本 12345678910111213141516# 添加 PPA 源sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get update# 安装高版本sudo apt-get install gcc-11 #(大版本号即可)sudo apt-get install g++-11# 删除原链接cd /usr/binrm /usr/bin/gccrm /usr/bin/g++# 添加软连接ln -s gcc-11 gccln -s g++-11 g++ 添加环境变量 1source /usr/local/Ascend/ascend-toolkit/set_env.sh 编译 123456# 克隆项目 git clone --recursive https://github.com/Microsoft/onnxruntime.git cd onnxruntime# 编译./build.sh --allow_running_as_root --config RelWithDebInfo --build_shared_lib --parallel --use_cann --build_wheel 若想在后台运行编译过程 1234setsid ./build.sh --allow_running_as_root --config RelWithDebInfo --build_shared_lib --parallel --use_cann --build_wheel &amp;&gt;/root/Projects/build.log &amp;# 实时监控日志tail -f ../build.log 若需要部署应用，可以将编译后的动态链接库和头文件进行安装 12345# 安装make -C build/Linux/RelWithDebInfo/ install# 卸载（不删除文件夹）cat install_manifest.txt | sudo xargs rm","link":"/2023/07/20/ONNXRuntime%E5%85%A5%E9%97%A8-%E5%A6%82%E4%BD%95%E7%BC%96%E8%AF%91ONNXRuntime/"},{"title":"OpenCV社区洞察","text":"OpenCV背景OpenCV是1998年在Intel公司内的CVL(计算机视觉库)项目，由Gary Bradski发起，并由Vadim Pisarevsky担任技术主管，于1999年开源，2000年首次公开发布。2008年OpenCV的核心成员加入Willow Garage和Itseez公司继续开发。Itseez公司在2016年被Intel收购，核心开发团队重回Intel。 目前主要由Intel公司赞助OpenCV核心开发团队，并且很多OpenCV的开发者是Intel的雇员。这是一个由Intel公司主导，OpenCV.org非盈利基金会运营的开源项目。2019年以来，核心开发团队由Intel，OpenCV中国团队和xperience.ai公司组成。 版本发布策略目前每6个月发布一次版本，社区没有明确说明每个版本的生命周期。 4.x版本 版本号 发布时间 时间间隔 4.8.0 2023.6.29 \\ 4.7.0 2022.12.28 6个月 4.6.0 2022.6.7 6个月 4.5.5 2021.12.25 6个月 4.5.4 2021.10.10 2个月 4.5.3 2021.7.6 3个月 4.5.2 2021.4.3 3个月 4.5.1 2020.12.22 4个月 4.5.0 2020.10.12 2个月 4.0.0版本发布于2018.11.18。 3.x版本 版本号 发布时间 时间间隔 3.4.20 2023.6.27（仅打Tag） \\ 3.4.19 2022.12.27（仅打Tag） 6个月 3.4.18 2022.6.5（仅打Tag） 6个月 3.4.17 2021.12.25（仅打Tag） 6个月 3.4.16 2021.10.10 2个月 3.4.15 2021.7.6 3个月 3.4.14 2021.4.2 3个月 3.4.13 2020.12.22 4个月 3.4.12 2020.10.12 2个月 3.x版本最新的一个release版本3.4.16发布时间为2021.10，最后一个tag版本3.4.20发布时间为2021.6。 3.0发布于2015.6.24。 2.x版本 2.x版本的最新一个release版本是2.4.13.6，发布于2018.2.26，从发布时间上看，已经不再维护。 社区没有明确说明每个大版本的支持周期 OpenCV基金会领导团队 Gary Bradski (Itseez, Intel） Anna Petrovicheva (Intel) Vladimir Dudnik (Intel) Stefano Fabri (Deeper) Tatiana Khanova (Xperience.ai) Satya Mallick (OpenCV CEO) Vadim Pisarevsky (Huawei) Vincent Rabaud (Google) Edgar Riba (farm-ng) Aleksandr Voron (N/A) 领导团队（leadership meeting)，每周三 8:00 am, 太平洋时间，通过Hangouts沟通，会议纪要记录在github的wiki上。 开发团队和贡献者社区github社区活跃开发者 姓名 社区职位 就职公司 Alexander Smorkalov 活跃commitor，合入PR数量众多 Xperience.AI Vadim Pisarevsky OpenCV技术负责人 华为 Alexander Alekhin 活跃开发者，reviewer，commitor Intel Ilya Lavrenov 活跃开发者 Itseez CTO Dmitry Kurtaev 活跃开发者，reviewer，commitor YADRO … … 小粒度特性和bug fix可以用issue跟踪，大粒度特性需要有进化提案跟踪。贡献社区需要参考OpenCV社区的贡献指导，所提交的代码需要符合社区编码规范。 领域主席 领域 姓名 单位 RISC-V Mingjie Xing 中国科学院软件研究所 人脸识别与分析 Weihong Deng 北京邮电大学 人体检测 Andrea Pennisi University of Antwerp 图像增强 Zhangyang “Atlas” Wang The University of Texas at Austin 形状检测 Qi Jia 大连理工大学 文档 Dr. Vikas Ramachandra Columbia University in the City of New York 辅助技术 Jagadish Mahendran Bovi.ag 官方论坛 社区交流可以在官方论坛上互动。 OpenCV合作伙伴 Intell, OpenCV 白金会员 黄金会员：Microsoft Azure, Google summer of Code, FUTUREWEI, 华为（成为黄金会员方式：捐献十万美金，开发者或者其他资源） 发展合作伙伴：KHADAS, ORBBEC, RunPod 合作联系方式：contact@opencv.ai（美国），admin@opencv.org.cn （中国） OpenCV中国团队OpenCV中国团队于2019年9月成立， 非营利目的，致力于OpenCV的开发、维护和推广工作。OpenCV中国团队由OpenCV项目发起人Gary Bradski担任团队顾问，OpenCV技术负责人Vadim Pisarevsky领导技术开发，OpenCV中文社区创始人于仕琪博士担任团队负责人。 国内负责人和核心开发成员均为于仕琪博士团队，并且是于仕琪的研究助理，主要社区提交为DNN相关内容。 姓名 职位 github id OpenCV贡献 社区职位 备注 吴佳 研究助理 kaingwade 1PR 38 ++ 0– 无 母自豪 研究助理，2018级研究生 zihaomu 79PR 42,381 ++ 22,986 – reviewer 冯远滔 研究助理，2018级研究生 fengyuentau 51PR 7,863 ++ 2,053 – reviewer DNN支持CANN后端作者 钟万里 研究助理 WanliZhong 18PR 561 ++ 147 – reviewer OpenCV欢迎外部公司合作，可由OpenCV中国团队指导，外部公司软件工程师开发，提交patch到OpenCV项目。可联系中国团队（admin@opencv.org.cn）洽谈。其中提到了在不同硬件平台上的OpenCV的加速，契合昇腾使能的诉求。 社区运作方式 代码仓库和版本控制：OpenCV代码托管在github上，使用git做版本管理，社区成员在这些仓库中提交代码和PR，有reviewer进行代码review，并最终由commitor合入代码。OpenCV有三个主要代码库： opencv：opencv主要代码库，包含关键数据结构和成熟算法，HAL方式在此库以3rd_party的方式贡献 opencv_contrib：opencv扩展模块库，依赖opencv_core，社区提交要求先进入此库，成熟后合入主库。cuda等算法均在此库，命名空间方式以独立模块方式在此库贡献 opencv_extra：opencv扩展数据库，存放测试数据，供测试使用 讨论和沟通：OpenCV社区使用（邮件列表？未找到）github，论坛进行技术讨论和沟通 问题追踪和解决：OpenCV使用github issue进行问题追踪： opencv - 库和稳定模块的一般问题，与构建相关的问题 opencv_contrib -实验模块及其依赖项的问题 opencv.org - 官方网站的问题 文档和教程：最新的版本使用Doxygen来展示文档，其中包含了使用教程 社区活动和会议：开发者可以参与谷歌代码之夏活动来提交新的想法和代码，社区领导团队每周三太平洋时间8:00 am在环聊上开展会议，并归档到wiki上。 教育和培训：社区联合Bigision提供了许多在线课程（收费），完成学习后可以获得毕业证书以及优秀证书，针对企业和组织也提供了培训计划。 昇腾接入方式贡献开源方式 HAL：OpenCV在core，imgproc，feature2d这三个模块都提供了HAL机制，通过include hal_replacement.hpp替换相关宏定义，决定真正的执行后端。 命名空间：使用独立模块，实现与cv相同的函数接口。使用命名空间的方式进行调用。 两种接入方式比较 比较项 HAL 命名空间 实现成本 低，进需要实现定义好的函数接口即可，不涉及Matrix对象，入参出参均为常见数据类型。 较高，需要自定义实现NPU上的Mat结构，代码生成等相关工作。 用户使用成本 对用户完全透明，无缝替换。 用户需要替换函数调用接口，有可能涉及Mat对象转换NPU Mat对象操作。 性能 每个算子执行前后均涉及内存数据搬迁，无法异步执行，效率低。 计算过程中算子无需搬迁，可使用异步执行，效率高。 现有实现 carotene，Nvdia实现的SIMD加速库。 CUDA加速。","link":"/2023/08/31/OpenCV%E7%A4%BE%E5%8C%BA%E6%B4%9E%E5%AF%9F/"},{"title":"OpenCV算子开发及其NPU调用方式","text":"OpenCV目前通过调用CANN提供的接口的方式调用NPU，其中调用的接口主要包括数据内存的申请、拷贝和释放、算子执行。 了解CANNCANN的官方介绍： CANN（Compute Architecture for Neural Networks）是华为针对AI场景推出的异构计算架构，对上支持多种AI框架，对下服务AI处理器与编程，发挥承上启下的关键作用，是提升昇腾AI处理器计算效率的关键平台。同时针对多样化应用场景，提供高效易用的编程接口，支持用户快速构建基于昇腾平台的AI应用和业务。 CANN中面向开发者的即为AscendCL，开发者通过AscendC编程，而CANN则根据编译后的指令通过任务调度将任务下发给不同的处理单元，通过驱动完成对计算资源的调用。这里计算资源主要指AI Core和AI CPU，根据处理数据的不同，即AI Core负责矩阵、向量、标量计算密集的算子计算，而AI CPU则负责非矩阵类、逻辑复杂的分支密集型计算，目前，AI Core还承担了部分无法执行在AI Core的计算密集算子计算。 OpenCV昇腾算子开发CANN主要的功能特性包括推理应用开发、模型训练和算子开发，OpenCV昇腾算子的开发目前属于推理应用开发，后续提升算子支持完整度过程中会加入自定义算子开发。 开发流程CANN应用开发基于AscendCL实现，因此应用开发的基础是掌握AscendCL的架构及基本概念和接口的典型调用流程。本篇主要集中于算子调用流程，媒体数据处理的详细解析见dvpp接口调用。 常用接口在OpenCV应用开发中，常用的算子包括ACL（去）初始化接口、设备设置接口、device内存操作接口、Stream管理接口和具体的算子接口。ACL（去）初始化接口用来初始化系统内部资源；设备设置接口用来获取device信息、指定或切换device等；device内存操作口用来实现device和host侧的数据搬移；Stream管理接口用来管理任务的并行，一个Stream内部的任务保序执行，即Stream根据发送过来的任务依次执行；不同Stream中的任务并行执行。具体的算子接口则实现具体的计算功能。 下面表格中为除具体算子接口外的常用接口列表，其详细用法参见昇腾文档。 算子类别 接口名称 功能 ACL（去）初始化接口 aclInit(const char *configPath) 初始化ACL系统，用在程序开始时 aclFinalize() 去初始化ACL系统，用在程序退出时 设备设置接口 aclrtGetDevice(int32_t *deviceId) 获取当前线程的目标设备ID aclrtResetDevice(int32_t deviceId) 重置当前操作的设备并释放设备资源 aclrtGetDeviceCount(uint32_t *count) 获取设备数量 device内存操作接口 aclrtMalloc(void **devPtr,size_t size,aclrtMemMallocPolicy policy) 申请设备内存（真实申请的内存是32bytes对齐的） aclrtFree(void *devPtr) 释放设备内存 aclrtMemcpy(void *dst, size_t destMax, const void *src,size_t count,aclrtMemcpyKind kind) HOST和DEVICE之间的同步内存复制 aclrtMemcpyAsync(void *dst, size_t destMax,const void *src,size_t count, aclrtMemcpyKind kind, aclrtStream stream) HOST和DEVICE之间的异步内存复制 aclrtMemcpy2d(void *dst,size_t dpitch,const void *src, size_t spitch,size_t width,size_t height,aclrtMemcpyKind kind) HOST和DEVICE之间二维矩阵的同步内存复制 aclrtMemcpy2dAsync(void *dst,size_t dpitch,const void *src, size_t spitch,size_t width,size_t height,aclrtMemcpyKind kind,aclrtStream stream) HOST和DEVICE之间二维矩阵的异步内存复制 aclrtMemset(void *devPtr, size_t maxCount, int32_t value, size_t count) 同步内存初始化 aclrtMemsetAsync(void *devPtr,size_t maxCount,int32_t value, size_t count,aclrtStream stream) 异步内存初始化 Stream管理接口 aclrtCreateStream(aclrtStream *stream) 创建一个Stream aclrtSynchronizeStream(aclrtStream stream) 阻塞应用程序运行，直到指定Stream中的所有任务都完成 QA如何确定算子执行在AI Core还是AI CPU？ 查看CANN算子清单 算子清单由于更新迭代问题不一定最准确，此时可以查看~/Ascend/ascend-toolkit/XXX（CANN版本号）/opp/built-in/op_impl/ai_core/tbe/config/ascendXXX（NPU型号）下的json文件，查看当前设备支持的AI Core算子清单；相应地，AI CPU的则位于/usr/local/Ascend/ascend-toolkit/XXX（CANN版本号）/opp/built-in/op_impl/aicpu/aicpu_kernel/config 如何打印详细日志？ 12345# 设置全局日志级别（0：DEBUG；1：INFO; 2：WARNING; 3：ERROR； 4：NULL（不输出））- export ASCEND_GLOBAL_LOG_LEVEL=0 # 是否开启日志打屏。开启后，日志将不会保存在log文件中，而是将产生的日志直接打屏显示。- export ASCEND_SLOG_PRINT_TO_STDOUT=1 参考 昇腾CANN文档 昇腾CANN算子开发揭秘","link":"/2023/11/25/OpenCV%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91%E5%8F%8A%E5%85%B6NPU%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"title":"从零开始编译OpenCV NPU教程","text":"从零开始编译OpenCV NPU教程本文介绍如何从零开始，成功编译OpenCV NPU项目。 本示例使用的机器为华为云昇腾310虚拟机。 123实例类型：AI加速型Ai1s操作系统：Ubuntu 18.04IDE：VSCode 1. 环境准备1.1 安装驱动及依赖按照昇腾虚拟机固件与驱动安装指引__卸载旧版驱动__和__安装Ascend 310驱动__（此处仅摘抄了需要执行的命令），此时先不要安装CANN，待准备好依赖的python环境后再安装。 123456789101112cd /usr/local/Ascend# 按照opp、ascend-tookit、driver的顺序，依次进入相关目录的script目录中，执行uninstall.sh文件# 卸载完成后，重启VM# 安装driver./A300-3010-npu-driver_21.0.4_linux-x86_64.run --full# 检查安装结果，显示两块OK的ascend 310卡npu-smi info# 如果是非root用户，需要添加用户组# gid: 组id; HwHiAiUser: 组名; uid: 用户id(可通过 id usrName查询); usrName:用户名usermod -a -G HwHiAiUser/gid usrName/uid# 安装依赖apt-get install -y gcc g++ make cmake zlib1g zlib1g-dev openssl libsqlite3-dev libssl-dev libffi-dev unzip pciutils ne 1.2 Anaconda安装及配置从Anaconda官网下载x86_64对应的Anaconda，使用bash命令安装： 123bash Anaconda3-2023.07-2-Linux-x86_64.sh# 输入一次安装目录 /home/用户目录/anaconda3后，一直enter+yes# conda安装完毕后，重启终端，conda命令生效 由于国内下载conda资源过慢，建议配置清华源anaconda镜像提高下载速度。 1234567891011121314151617181920# 修改用户目录下的.condarc文件vim ~/.condarc# 修改.condarc内容为如下：channels: - defaultsshow_channel_urls: truedefault_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/# 至此完成清华源anaconda镜像配置。 1.3 python虚拟环境安装新建python版本为3.X的conda虚拟环境___【CANN目前只支持python3.7/3.8/3.9版本】___ 12345678910111213# 新建虚拟环境conda create -n YOUR_ENV_NAME python=3.9# 激活环境，在新环境中安装其他依赖conda activate YOUR_ENV_NAME# 升级pippip3 install --upgrade pip# 安装pip依赖pip3 install attrs numpy decorator sympy cffi pyyaml pathlib2 psutil protobuf scipy requests# 修改用户目录的.bashrc文件，使得虚拟环境自动激活vim ~/.bashrc# 将“ conda activate YOUR_ENV_NAME ”添加至.bashrc文件末尾# 退出vim并激活.bashrc使其生效source ~/.bashrc 1.4 CANN安装注意 开发套件安装，从 CANN 社区版下载-昇腾社区下载__6.3.RC2.alpha003__对应的CANN。 123456789# 安装cann toolkit./Ascend-cann-toolkit_6.3.RC2.alpha003_linux-x86_64.run --install# 添加环境变量# 编辑用户目录下的.bashrc文件vim ~/.bashrc# 将以下内容添加至.bashrc文件末尾source ~/Ascend/ascend-toolkit/set_env.sh# 退出vim并激活.bashrc使其生效source ~/.bashrc 安装好驱动之后，将系统用户添加到组里，保证在usrName用户下可以正常使用驱动。 1usermod -a -G HwHiAiUser/gid usrName/uid 2. OpenCV下载及编译2.1 OpenCV项目下载OpenCV为保证官方发行版的稳定性，使用另外的仓opencv_contrib接收贡献的功能，因此opencv和opencv_contrib均需下载。 123456# 克隆opencv项目到本地git clone https://github.com/opencv/opencv.git# 进入opencv路径cd opencv# 克隆opencv_contrib项目到opencv路径下git clone https://github.com/opencv/opencv_contrib.git 2.2 项目配置在opencv项目路径下新建.vscode文件夹，新建调试配置文件launch.json，写入以下内容（注释为解析，不需要写入）： 123456789101112131415161718192021222324252627{ &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;ascend&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, // 启动程序or连接到已在运行的实例。launch：启动；attach：附加 &quot;cwd&quot;: &quot;${workspaceFolder}&quot;, // 调试器启动的应用程序的工作目录 &quot;program&quot;: &quot;~/anaconda3/envs/py39/bin/python&quot;, // 需要调试的程序，此处为conda虚拟环境的python &quot;args&quot;: [ &quot;~/workspace/opencv/test.py&quot;, // 调试时传递给程序的参数 ], &quot;MIMode&quot;: &quot;gdb&quot;, // 调试器类型 gdb/lldb；此处为gdb &quot;targetArchitecture&quot;: &quot;x86_64&quot;, &quot;stopAtEntry&quot;: false, // 调试时是否停在程序入口 &quot;externalConsole&quot;: false, // true：输出到外部终端；false：只输出到软件终端 &quot;setupCommands&quot;: [ // 设置GDB或LLDB所需执行的命令 { &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true } ] } ]} 同样地，.vscode文件夹下新建配置文件setting.json，写入cmake配置项和文件关联配置项如下（注释为解析，不需要写入）： 1234567891011121314151617181920212223242526272829303132333435{ &quot;cmake.configureArgs&quot;: [ &quot;-DCMAKE_INSTALL_PREFIX=~/workspace/opencv/build/install&quot;, // 配置安装目录 &quot;-DWITH_DEBUG=0&quot;, // 是否以debug方式编译项目 &quot;-DBUILD_WITH_DEBUG_INFO=0&quot;, // 编译是否输出debug info &quot;-DOPENCV_EXTRA_MODULES_PATH=~/workspace/opencv/opencv_contrib/modules&quot;, // OpenCV其他模块的路径，将opencv_contrib modules的路径配置进来 &quot;-DWITH_CUDA=0&quot;, // 是否有CUDA &quot;-DWITH_CANN=1&quot;, // 是否有CANN &quot;-DPYTHON3_EXECUTABLE=~/anaconda3/envs/$YOUR_ENV_NAME$/bin/python&quot;, // python可执行文件的路径 &quot;-DPYTHON_LIBRARY=~/anaconda3/envs/$YOUR_ENV_NAME$&quot;, // python库路径 &quot;-DPYTHON_INCLUDE_DIR=~/anaconda3/envs/$YOUR_ENV_NAME$/include/python3.9&quot;, // python包含路径 /* 此部分为与opencv npu开发无关的库，关闭其编译以加快编译速度 */ &quot;-DBUILD_opencv_wechat_qrcode=OFF&quot;, &quot;-DBUILD_opencv_xfeatures2d=OFF&quot;, &quot;-DBUILD_opencv_face=OFF&quot;, &quot;-DBUILD_opencv_dnn=OFF&quot;, &quot;-DBUILD_opencv_features2d=OFF&quot;, &quot;-DBUILD_opencv_bioinspired=OFF&quot;, &quot;-DBUILD_opencv_flann=OFF&quot;, &quot;-DBUILD_opencv_hdf=OFF&quot;, &quot;-DBUILD_opencv_hfs=OFF&quot;, &quot;-DBUILD_opencv_fuzzy=OFF&quot;, &quot;-DBUILD_opencv_intensity_transform=OFF&quot;, &quot;-DBUILD_opencv_line_descriptor=OFF&quot;, &quot;-DBUILD_opencv_ml=OFF&quot;, &quot;-DBUILD_opencv_phase_unwrapping=OFF&quot;, &quot;-DBUILD_opencv_photo=OFF&quot;, &quot;-DBUILD_opencv_quality=OFF&quot;, &quot;-DBUILD_opencv_tracking=OFF&quot;, &quot;-DWITH_CAROTENE=OFF&quot;, &quot;-DWITH_IPP=OFF&quot;, /* ************************************************* */ &quot;-DBUILD_DOCS=ON&quot;, // 是否构建文档 ],} 2.3 项目编译通过vscode安装C/C++、CMake、CMake Tools、Python拓展，由于项目配置项较多，通过2.2 项目配置+CMake Tools对项目进行编译。 利用CMake Tool进行编译示例界面。configure根据2.2 项目配置中指定的编译选项进行配置。build则实现项目编译。 完成cmake configure之后，请检查是否包含CANN（下图黄色高亮），python是否指向YOUR_ENV_NAME虚拟环境（下图绿色高亮），如果这些答案均为“是”，则关键配置正确。 build成功的标志则为[build] Build finished with exit code 0。 项目编译完成后，在build目录下会出现python_loader文件夹，在终端中执行python_loader路径下的setup.py，即可将opencv安装到python虚拟环境中，从而实现python调用opencv。 12345678910# 进入python_loader目录（当前目录为opencv）cd ./build/python_loader# 安装opencv到python（注意当前python环境应为YOUR_ENV_NAME虚拟环境）python setup.py develop# 验证python中opencv是否安装好python&gt;&gt;&gt;import cv2&gt;&gt;&gt;# 如上即为安装成功，可以愉快的开启开发了# 如果提示找不到cv2则安装失败:( 检查一下编译是否有问题吧","link":"/2023/09/01/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E8%AF%91OpenCV-NPU%E6%95%99%E7%A8%8B/"},{"title":"如何向开源项目提交 PR","text":"作者：@zhangsibo1129 以 ONNX Runtime 开源项目为例，介绍如何向开源项目提交 PR 开发分支管理1. 开发仓库关系在贡献开源的场景下，开发涉及到三个仓库：Github-Upstream 上游仓库，Github-Origin 个人远程仓库，Local Repository 本地仓库。如下图所示，以 ONNX Runtime 开源项目为例，上游仓库对应 microsoft/onnxruntime，个人远程仓库对应 zhangsibo1129/onnxruntime，本地仓库对应着克隆到本地计算机的代码 三者关系如图，首先从 Github-Upstream 上游仓库 Fork 一个个人远程仓库 Github-Origin，并从上游仓库 clone/fetch 最新提交信息同步到本地仓库；在本地仓库创建开发分支，进行代码开发，开发完毕后将代码 push 到个人远程仓库的分支；最后从个人远程仓库向上游仓库主干分支提交 Pull Request。 2. 个人仓库创建进入 ONNX Runtime 开源项目主页，Fork 该项目到个人仓库 克隆代码到本地仓库，设置上游仓库和个人远程仓库 1234567891011121314# 从 upstream 克隆项目到本地git clone https://github.com/microsoft/onnxruntime.git# 删除当前远程仓库git remote rm origin# 添加 upstream 远程仓库git remote add upstream git@github.com:microsoft/onnxruntime.git# 添加 origin 远程仓库git remote add origin git@github.com:zhangsibo1129/onnxruntime.git# 查看远程仓库git remote -v 显示如下，配置完毕 1234origin git@github.com:zhangsibo1129/onnxruntime.git (fetch)origin git@github.com:zhangsibo1129/onnxruntime.git (push)upstream git@github.com:microsoft/onnxruntime.git (fetch)upstream git@github.com:microsoft/onnxruntime.git (push) 3. 开发分支创建新建并切换到本地开发分支 1git checkout -b my_dev_branch 本地代码开发1. 从上游获取更新同步 upstream 与 origin 仓库的 main 分支 1234567891011# 获取 upstream 仓库的更新git fetch upstream # 切换到本地 main 分支git checkout main# 将 upstream/main 分支合入本地 main 分支git merge upstream/main# 将本地 main 分支推送到 origin 仓库 main 分支git push origin main 2. 变基到最新分支将当前开发分支进行变基操作 12345# 切换到本地开发分支git checkout my_dev_branch# 变基到最新的 upstream main 分支git rebase upstream/main 3. 代码开发修改onnxruntime/core/providers/cann/cann_execution_provider.cc代码，运行git diff。 提交代码并创建 PR代码开发完毕，但只存在本地仓库中，要先推送到个人远程仓库，才能向上游仓库提交 PR 1. 推送到个人远程仓库提交代码到本地开发分支 12345# 添加修改文件git add onnxruntime/core/providers/cann/cann_execution_provider.cc# 向本地仓库提交更改git commit -m &quot;Fix registration of Identity operator&quot; 将本地开发分支推送到远程个人仓库 1git push origin my_dev_branch 此时，修改后的代码已经合入了远程个人仓库的开发分支 origin/my_dev_branch 2. 向上游创建 PR创建 PR 的作用是将 origin/my_dev_branch 合入 upstream/main，从而实现将自己开发的代码贡献给上游社区，该操作在 Github 网页上完成，如下图所示在个人远程仓库页面创建新 PR 选择正确的分支，依次按提示点击 review 以及静态检查、CI 构建等通过后，committer 会进行合入操作，合入成功显示如下信息","link":"/2023/08/03/%E5%A6%82%E4%BD%95%E5%90%91%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%8F%90%E4%BA%A4-PR/"},{"title":"如何构建一个RPM包","text":"构建一个RPM包1. rpmdevtools工具及SPEC文件一些基础点 可以直接从下一章节看网上找了好多相关的教程，RedHat的教程应该是最官方的。目前没找到如何生成压缩包的，本文使用setuptools生成还有说使用pyinstaller生成可执行文件然后获取其依赖并压缩的，没有测试这个 rpmdevtools工具 构建主要用的就是SPEC文件和源文件，将其放到对应的文件夹下执行构建命令 首先创建RPM的工作环境，便捷的就是安装rpmdevtools工具 执行rpmdev-setuptree命令后结果如下 12345678# rpmdev-setuptree# tree ~/rpmbuild//root/rpmbuild/├── BUILD├── RPMS├── SOURCES├── SPECS└── SRPMS 工作环境目录用途如下 目录 用途 BUILD 构建时生成的各种信息都在这里 RPMS 构建出的二进制包 SOURCES 构建用的源文件放这里，如压缩包、补丁文件等 SPECS 构建用的.spec文件放这里 SRPMS 构建出的源码包 BUILDROOT 构建过程中创建，保存%install阶段安装的文件 SPEC文件 SPEC文件可以分为Preamble和Body两部分 Preamble: SPEC指令 用途 Name package name Version version number Release NA Summary NA License NA URL 该包的上游网址 Source0 源文件 Patch0 数量可变 BuildArch 构建依赖的环境 BuildRequires 构建所需的依赖包 Requires 运行所需的依赖包 Body: SPEC指令 用途 %description NA %prep 构建前的一些命令 %build 构建时执行的命令 %install 最终安装目录 %check 测试软件命令 %files 最终会安装在系统的文件 %changelog NA 2.构建一个简单的hello world rpm包 编写py文件 还是最通用的hello world 12345678#!/usr/bin/python# -*- coding: utf-8 -*-def my_print(): print('hello world')if __name__ == '__main__': my_print() 编写setup.py文件 前面是license 命令是setuptools.setup setup中哪些可以不需要还没有完全搞清楚，当前这样没有问题 123456789101112131415161718192021222324252627282930313233343536373839# Copyright (c) 2013 Hewlett-Packard Development Company, L.P.## Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or# implied.# See the License for the specific language governing permissions and# limitations under the License.# THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDITimport setuptoolssetuptools.setup( name='myrpm', version='0.1.1', license='Apache License 2.0', classifiers=[ 'Development Status :: 5 - Production/Stable', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: Implementation :: PyPy', 'Topic :: Software Development :: Libraries :: Python Modules', ], packages=['myrpm'], include_package_data=True, zip_safe=False, platforms='any',) 目录结构 12345python-myrpm/├── myrpm│ ├── __init__.py│ └── myrpm.py└── setup.py 生成压缩包 在python-myrpm/目录下执行 1python setup.py sdist 执行后目录如下 生成了myrpm-0.1.1.tar.gz压缩文件 感兴趣可以解压看看 我们就使用这个压缩文件作为源码构建RPM包 12345678910111213python-myrpm/├── dist│ └── myrpm-0.1.1.tar.gz├── myrpm│ ├── __init__.py│ └── myrpm.py├── myrpm.egg-info│ ├── dependency_links.txt│ ├── not-zip-safe│ ├── PKG-INFO│ ├── SOURCES.txt│ └── top_level.txt└── setup.py 对应的还有一些其他命令，install是使用源码安装、build是构建、 clean是清理build和bdist生产的临时目录、bdist是生成二进制压缩包、 sdist是源码压缩包，–formats可以指定压缩包格式 1234python setup.py buildpython setup.py installpython setup.py cleanpython setup.py bdist 制作SPEC文件 优先使用工具创建 在SPECS目录下执行如下命令 生成myrpm.spec文件 1rpmdev-newspec myrpm.spec 修改SPEC文件如下 12345678910111213141516171819202122232425262728293031323334353637%global debug_package %{nil}Name: myrpmVersion: 0.1.1Release: 1Summary: simple python rpmLicense: Apache-2.0URL: https://docs.openstack.org/tooz/latest/Source0: myrpm-0.1.1.tar.gzBuildArch: noarchBuildRequires: python3-setuptools%descriptionA simple python rpm%prep%autosetup -n %{name}-%{version}%build%py3_build%install%py3_installpushd %{buildroot}if [ -d usr/lib ]; then find usr/lib -type f -printf &quot;/%h/%f\\n&quot; &gt;&gt; filelist.lstfipopdmv %{buildroot}/filelist.lst .%files -n %{name} -f filelist.lst%dir %{python3_sitelib}/*%changelog* Thu Sep 21 2023 XXX &lt;XXX@gmail.com&gt;- init 其中 %global debug_package %{nil} 是缺少debug相关文件 当前不关注使用该命令忽略其报错 Source0填充包名 %prep 填充%autosetup -n %{name}-%{version} %build 填充%py3_build %install 填充%py3_install pushd 这里是把最终会安装在系统的文件写入到filelist.lst中 %file 是指明哪些文件会安装在系统，如果有遗漏，构建是会提示 ‘error: Installed (but unpackaged) file(s) found’的报错 %license 和 %doc 当前不关注忽略 对SPEC文件中更高级的修改需要进一步探索 构建RPM包 把第4步和第5步中的源码压缩包、SPEC文件分别放到SOURCE和SPECS目录下 12345678~/rpmbuild├── BUILD├── RPMS├── SOURCES│ └── myrpm-0.1.1.tar.gz├── SPECS│ └── myrpm.spec└── SRPMS 在SPECS目录下执行rpmbuild命令 1rpmbuild -ba myrpm.spec 构建成功后使用如下命令查询结果 123456tree /root/rpmbuild/*RPMS/root/rpmbuild/RPMS└── noarch └── myrpm-0.1.1-1.noarch.rpm/root/rpmbuild/SRPMS└── myrpm-0.1.1-1.src.rpm RPM包使用 使用rpm -ivh 安装rpm包，安装后就可以import了 使用rpm -qa | grep 查询安装的包 使用rpm -e 卸载安装的包 当前发现卸载是会在/usr/lib/python3.9/site-packages/中残留__pycache__文件夹 暂时无法解决，试了下别的包也有这个问题 3.增量构建RPM包增量构建可能描述的不准确，实际上是以git.patch的形式添加自己对已有RPM包的修改，然后构建 这种构建要使用源码包RPM包一般分为二进制和源码包(后缀为.src.rpm)包名中noarch字段表示无环境依赖 源码包可以通过rpm2cpio命令解压.src.rpm的包得到也可以找到相关的SPEC文件，通过URL获取对应的压缩包 以上一章节中构建的RPM包为例，更改my_print的打印内容 解压rpm包获取源码压缩包 123456# rpm2cpio myrpm-0.1.1-1.src.rpm | cpio -div -D srcrpm# tree.└── srcrpm ├── myrpm-0.1.1.tar.gz └── myrpm.spec 其中 -D 参数为指定解压的目录 解压源码 解压后进入到myrpm目录 123456789101112131415161718# tar -vxf myrpm-0.1.1.tar.gz# treesrcrpm/├── myrpm-0.1.1│ ├── myrpm│ │ ├── __init__.py│ │ └── myrpm.py│ ├── myrpm.egg-info│ │ ├── dependency_links.txt│ │ ├── not-zip-safe│ │ ├── PKG-INFO│ │ ├── SOURCES.txt│ │ └── top_level.txt│ ├── PKG-INFO│ ├── setup.cfg│ └── setup.py├── myrpm-0.1.1.tar.gz└── myrpm.spec 生成git patch文件 当前在srcrpm/myrpm-0.1.1/myrpm目录，示例如下 选择要修改的文件初始化git仓 完成你的修改，且不要add git diff生成补丁文件 12345678910# git init# git add myrpm.py# git commit -m &quot;init&quot;# vi myrpm.py# git diff myrpm.py &gt; myrpm.patch# tree.├── __init__.py├── myrpm.patch└── myrpm.py 修改SPEC文件 需要修改或者添加的字段如下： 12345678910111213141516171819202122232425262728293031323334index 5869db2..cb7fcb8 100644--- a/myrpm.spec+++ b/myrpm.spec@@ -1,12 +1,13 @@Name: myrpmVersion: 0.1.1-Release: 1+Release: 2Summary: simple python rpmLicense: Apache-2.0URL: https://docs.openstack.org/tooz/latest/Source0: myrpm-0.1.1.tar.gz+Patch01: myrpm.patchBuildArch: noarchBuildRequires: python3-setuptools@@ -15,7 +16,7 @@ BuildRequires: python3-setuptoolsA simple python rpm%prep-%autosetup -n %{name}-%{version}+%autosetup -n %{name}-%{version} -p1%build@@ -38,5 +39,8 @@ mv %{buildroot}/filelist.lst .%changelog+* Fri Sep 22 2023 xxx &lt;xxx@gmail.com&gt; - 0.1.1-2+- change print content+* Thu Sep 21 2023 xxx &lt;xxx@gmail.com&gt; - 0.1.1-1 构建 构建时将patch文件补充到SOURCES目录中，其他与上一章节相同 如果遇到’No file to patch. Skipping patch.’的报错 大概率是patch文件中的目录有问题 如当前示例中，patch文件中的目录为a/myrpm.py和b/myrpm.py 并且构建是会报错，将目录改为a/myrpm/myrpm.py和b/myrpm/myrpm.py即可 4.部分宏的对应值 宏 值 %{_sysconfdir} /etc %{_prefix} /usr %{_exec_prefix} %{_prefix} %{_bindir} %{_exec_prefix}/bin %{_lib} lib (lib64 on 64bit systems) %{_libdir} %{_exec_prefix}/%{_lib} %{_libexecdir} %{_exec_prefix}/libexec %{_sbindir} %{_exec_prefix}/sbin %{_sharedstatedir} /var/lib %{_datadir} %{_prefix}/share %{_includedir} %{_prefix}/include %{_oldincludedir} /usr/include %{_infodir} /usr/share/info %{_mandir} /usr/share/man %{_localstatedir} /var %{_topdir} %{getenv:HOME}/rpmbuild %{_builddir} %{_topdir}/BUILD %{_rpmdir} %{_topdir}/RPMS %{_sourcedir} %{_topdir}/SOURCES %{_specdir} %{_topdir}/SPECS %{_srcrpmdir} %{_topdir}/SRPMS %{_buildrootdir} %{_topdir}/BUILDROOT %{_var} /var %{_tmppath} %{_var}/tmp %{_usr} /usr %{_usrsrc} %{_usr}/src %{_docdir} %{_datadir}/doc","link":"/2023/09/22/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AARPM%E5%8C%85/"},{"title":"如何部署OpenStack","text":"安装OpenStack1. 使用oos工具安装oos(openEuler OpenStack SIG)是OpenStack SIG提供的命令行工具。安装oos工具，使用纳管的方式部署OpenStack环境，版本22.03-lts-sp2。 若提示无该版本，可在oos工具安装路径(oos/commands/environment/constants.py:OE_OS_RELEASE)添加该版本。该问题已修复，发布版本暂未更新。 安装oos工具 pip install openstack-sig-tool 创建oos环境 123# sshpass在`oos env create`过程中被使用，用于配置对目标主机的免密访问dnf install sshpassoos env manage -r 22.03-lts-sp2 -i TARGET_MACHINE_IP -p TARGET_MACHINE_PASSWD -n test-oos 替换TARGET_MACHINE_IP为目标机ip (使用ifconfig查看，如eth0的ip)、TARGET_MACHINE_PASSWD为目标机密码，即登陆当前环境的密码。 部署OpenStack 1&gt; 对于禁止密码登陆的机器，需要手动注入公匙 (oos/etc/key_pair/id_rsa.pub) 到~/.ssh/authorized_keys中，否则下面的命令会报错 2&gt; 安装cinder时需要有对应的磁盘/dev/vdb 3&gt; 其他安装可参考流程/usr/local/etc/oos/playbooks/entry.yaml 1oos env setup test-oos -r wallaby 安装完毕后可使用如下命令创建虚拟机 123456openstack flavor create --disk 1 --vcpus 2 --ram 1024 --id 1 --public my-flavorwget http://download.cirros-cloud.net/0.5.2/cirros-0.5.2-aarch64-disk.img -O cirros-0.5.2.imgopenstack image create --disk-format qcow2 --container-format bare --file ./cirros-0.5.2.img --public my-image -c id -f valueopenstack network create --external --share public-network --provider-network-type flat --provider-physical-network provider --default -c id -f valueopenstack subnet create --network public-network --allocation-pool start=10.100.100.189,end=10.100.100.239 --dns-nameserver 100.125.128.250 --gateway 10.100.100.1 --subnet-range 10.100.100.0/24 public-subnetopenstack server create --flavor my-flavor --image my-image --network public-network --password root my-server 1openstack server list 创建虚拟机后通过openstack server list命令查询虚拟机信息，回显会打印虚拟机id和ip 可使用virsh console 或ssh 命令连接虚拟机 2. 使用devstack安装使用devstack部署OpenStack，干净的环境大概率不会报错 安装步骤如下(master分支) 安装前准备 12345678910111213141516171819202122232425262728cd /opt/git clone https://opendev.org/openstack/devstack.git/opt/devstack/tools/create-stack-user.shchown -R stack:stack /opt/devstackchmod -R 755 /opt/devstackchmod -R 755 /opt/stack切换stack用户su stack确保stack用户的PATH环境变量包含了`/usr/sbin`PATH=$PATH:/usr/sbin新增配置文件vi /opt/devstack/local.conf[[local|localrc]]DATABASE_PASSWORD=rootRABBIT_PASSWORD=rootSERVICE_PASSWORD=rootADMIN_PASSWORD=rootOVN_BUILD_FROM_SOURCE=True# arm环境增加如下配置[[post-config|$NOVA_CONF]][libvirt]cpu_mode=customcpu_model=cortex-a72 devstack的master分支要求libvirt版本大于7.0 arm环境安装软件包edk2时缺少arm配置，建议使用下面的yum源安装libvirt和edk2相关软件包 https://eur.openeuler.openatom.cn/coprs/g/sig-openstack/Libvirt-7.X/repo/openeuler-22.03_LTS/group_sig-openstack-Libvirt-7.X-openeuler-22.03_LTS.repo 部署OpenStack 进入/opt/devstack目录，执行./stack.sh，等待部署完成 日志 devstack将日志生成到文件需要在部署前在local.conf中添加配置 未配置日志内容可使用systemd的方法查看日志，如查看nova-compute 服务的日志，服务名称可在/etc/systemd/system目录下查看， 其名称携带devstack@前缀，如下图所示 systemd日志查看命令举例如下： 1journalctl --unit devstack@n-cpu.service systemd调试方法 注：退出调试重启systemd服务时，一定要删除断点 nova-compute调试举例如下： 1&gt; 在对应的安装目录文件设置断点 import pdb;pdb.set_trace() 2&gt; 停止systemd服务 systemctl stop devstack@n-cpu.service 3&gt; 执行启动服务 查看对应服务，在终端1执行该命令 4&gt; 调试 在终端2执行OpenStack创建服务命令，代码会停止在断点处 另外，对于uwsgi这种服务，可能需要加上--honour-stdin才能调试， 可使用uwsgi --help查看参数含义","link":"/2023/11/01/%E5%A6%82%E4%BD%95%E9%83%A8%E7%BD%B2OpenStack/"},{"title":"容器昇腾NPU跑通llama2-7B","text":"作者：@Yikun 0. 前置条件根据 https://github.com/cosdt/cosdt.github.io/issues/7 完成pytorch环境搭建 1234567(.llm-venv) # npu-smi info(.llm-venv) # python3 -c &quot;import torch;import torch_npu; a = torch.randn(3, 4).npu(); print(a + a);&quot;Warning: Device do not support double dtype now, dtype cast repalce with float.tensor([[ 1.2800, 1.3105, 0.4513, -1.1650], [ 3.5199, -0.2590, 2.6664, -1.9602], [ 2.3262, -2.4671, 2.3252, -2.1502]], device='npu:0') 1. 安装Transformer1234python3 -m pip install --upgrade pippip install transformers accelerate xformers# Need &quot;sentencepiece&quot; and &quot;protobuf==3.20.0&quot; when convert_llama_weights_to_hfpip install sentencepiece protobuf==3.20.0 2. 准备llama模型准备模型： 123456789101112131415161718# tree llama/llama-2-7b/llama/llama-2-7b/├── checklist.chk├── consolidated.00.pth└── params.jsoncd llama/llama-2-7bmkdir 7Bmv *.* 7Bcp ../tokenizer.model .# tree -h llama/llama-2-7b/llama/llama-2-7b/|-- [4.0K] 7B| |-- [ 100] checklist.chk| |-- [ 13G] consolidated.00.pth| `-- [ 102] params.json`-- [488K] tokenizer.model 转换模型： 12# find / -name convert_llama_weights_to_hf.py/root/.llm-venv/lib/python3.8/site-packages/transformers/models/llama/convert_llama_weights_to_hf.py 1python /root/.llm-venv/lib/python3.8/site-packages/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir llama/llama-2-7b --model_size 7B --output_dir transformer/llama-2-7b 生成的模型结构如下： 1234567891011# tree -h transformer/llama-2-7b/transformer/llama-2-7b/|-- [ 578] config.json|-- [ 132] generation_config.json|-- [9.3G] pytorch_model-00001-of-00002.bin|-- [3.3G] pytorch_model-00002-of-00002.bin|-- [ 26K] pytorch_model.bin.index.json|-- [ 411] special_tokens_map.json|-- [1.8M] tokenizer.json|-- [488K] tokenizer.model`-- [ 745] tokenizer_config.json 3. 运行模型123456789101112131415161718192021222324from transformers import AutoTokenizer, LlamaForCausalLMimport torchimport torch_npu# Avoid ReduceProd operator core dump, see more in: https://github.com/cosdt/llm/issues/4option={}option[&quot;NPU_FUZZY_COMPILE_BLACKLIST&quot;]=&quot;ReduceProd&quot;torch.npu.set_option(option)npu_id = 0torch.npu.set_device(0)device = &quot;npu:{}&quot;.format(npu_id)model_path = &quot;/opt/yikun/transformer/llama-2-7b&quot;model = LlamaForCausalLM.from_pretrained(model_path).to(device)tokenizer = AutoTokenizer.from_pretrained(model_path)prompt = &quot;Deep learning is&quot;inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;).to(device)generate_ids = model.generate(inputs.input_ids, max_length=50)tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]'Deep learning is a branch of machine learning that is based on artificial neural networks. Deep learning is a subset of machine learning that is based on artificial neural networks. Neural networks are a type of machine learning algorithm that is inspired by the structure and' 踩到的坑： torch.npu.set_device: 设置错NPU ID后，会一直报错，即使改回来也会报错: https://github.com/cosdt/llm/issues/3 torch ReduceProd算子问题：https://github.com/cosdt/llm/issues/4 import transformer必须先于torch和torch_npu: https://github.com/cosdt/llm/issues/5","link":"/2023/08/18/%E5%AE%B9%E5%99%A8%E6%98%87%E8%85%BENPU%E8%B7%91%E9%80%9Allama2-7B/"},{"title":"容器环境安装PyTorch Ascend NPU","text":"作者：@Yikun 本文介绍如何在容器内安装CANN、PyTorch、PyTorch Ascend Adapter。 1. 构建基础容器123456789FROM ubuntu:20.04ENV DEBIAN_FRONTEND noninteractiveENV DEBCONF_NONINTERACTIVE_SEEN trueRUN sed -i 's/ports.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list &amp;&amp; \\ apt update &amp;&amp; \\ apt install -y adduser sudo vim gcc g++ cmake make gdb git tmux openssh-server net-tools iputils-ping python3 python3-venv python3-setuptools gcc python3-dev patchelf tree &amp;&amp; \\ apt remove -y cmake 1.1 构建并进入容器12345678910# 构建容器docker build -t ubuntu-20.04-yikun -f /data/disk3/yikun/Dockerfile .# 启动容器docker run --network host --name yikun --device /dev/davinci5 --device /dev/davinci_manager --device /dev/devmm_svm --device /dev/hisi_hdc -v /usr/local/dcmi:/usr/local/dcmi -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi -v /usr/local/Ascend/driver/lib64/:/usr/local/Ascend/driver/lib64/ -v /data/disk3/yikun:/opt/yikun -ti ubuntu-20.04-yikun:latest bash# 退出容器ctrl+p q# 通过exec进入容器docker exec -ti yikun bashexport LD_LIBRARY_PATH=/usr/local/Ascend/driver/lib64/common/:/usr/local/Ascend/driver/lib64/driver/:$LD_LIBRARY_PATHnpu-smi info 1.2 容器内安装CANN12345wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C13SPC701/Ascend-cann-nnae_7.0.RC1.alpha001_linux-aarch64.runchmod +x Ascend-cann-nnae_7.0.RC1.alpha001_linux-aarch64.runAscend-cann-nnae_7.0.RC1.alpha001_linux-aarch64.run --install 1.3 环境变量加到bashrc12345echo &quot;&quot;&quot;source /usr/local/Ascend/ascend-toolkit/set_env.shexport LD_LIBRARY_PATH=/usr/local/Ascend/driver/lib64/common/:/usr/local/Ascend/driver/lib64/driver/:\\$LD_LIBRARY_PATHsource ~/.llm-venv/bin/activate&quot;&quot;&quot; &gt;&gt; ~/.bashrc 2. 初始化PyThon环境(venv为例)12345678910111213python3 -m venv ~/.llm-venvsource ~/.llm-venv/bin/activate# 换PyPI源mkdir ~/.pip/echo &quot;&quot;&quot;[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=[mirrors.aliyun.com](http://mirrors.aliyun.com/)&quot;&quot;&quot; &gt; ~/.pip/pip.conf# 安装PyTorch基础依赖pip install cmake ninja 3. 安装PyTorch1234567git clone https://github.com/pytorch/pytorch.gitcd pytorchgit reset 5913437a40a6e45ab7e164afb7c6ec930dd40b2f --hardexport USE_CUDA=0export USE_XNNPACK=0pip install -r ./requirements.txtpython setup.py develop 1234# 如果遇到国内网络无法访问export http_proxy=http://127.0.0.1:1234;export https_proxy=$http_proxy;no_proxy=127.0.0.1git submodule update --init --recursiveunset http_proxy;unset https_proxy; 4. 安装PyTorch NPU12345678910111213141516git clone https://gitee.com/ascend/pytorch.git ascend-pytorchgit reset 81ece7b664adc28e698044d0e9091d39a1a6dfa6 --hardpip3 install pyyaml wheel decorator snippy# 确保python3.8是venv里的python，否则`cd ~/.llm-venv/bin/;ln -sf python3 python3.8`bash ci/build.sh --python=3.8# dist下面会生成whlpip3 install --upgrade dist/torch_npu-2.1.0-cp38-cp38-linux_aarch64.whl# 进入到非pytorch目录，测试cd ~ python3 -c &quot;import torch;import torch_npu; a = torch.randn(3, 4).npu(); print(a + a);&quot;Warning: Device do not support double dtype now, dtype cast repalce with float.tensor([[-2.5684, -1.0355, 2.1467, -1.9409], [-0.8765, -2.1909, 1.6815, 2.1013], [ 7.0935, 3.7160, 1.6914, -0.1912]], device='npu:0')","link":"/2023/08/08/%E5%AE%B9%E5%99%A8%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85PyTorch-Ascend-NPU/"},{"title":"昇腾虚拟机固件与驱动安装","text":"作者：@wangxiyuan 华为云目前提供了基于Ascend 310的虚拟机，实例类型为Ai1，支持的OS为ubuntu 18.04和centos 7.6。本文以ubuntu 18.04的4U16G并搭载两块ascend 310的VM为例，说明如何初始化开发环境。 卸载旧版固件 华为云的Ai1实例默认已经安装了Ascend的驱动和lib库，但版本可能已过时，如果想使用新版的开发环境，则需要先删除旧版固件。 123# 进入/usr/local/Ascend，cd /usr/local/Ascend#按照opp、ascend-tookit、driver的顺序，依次进入相关目录的script目录中，执行uninstall.sh文件 卸载完成后，需要重启VM 安装驱动和开发库 从昇腾官方下载最新的驱动和开发包 CANN-NNRT(NNRT是推理运行时包，开发环境可以不用安装，已被toolkit集成） CANN-TOOLKIT Ascend 310 driver 下载对应的.run包，拷贝到VM中，赋予执行权限，按照driver、nnrt、toolkit的顺序依此安装。 1234567891011121314# 安装driver./A300-3010-npu-driver_21.0.4_linux-x86_64.run --full# 检查安装结果，显示两块OK的ascend 310卡npu-smi info# 安装nnrt./Ascend-cann-nnrt_5.1.RC2.alpha002_linux-x86_64.run --install：# 安装依赖apt-get install -y gcc g++ make cmake zlib1g zlib1g-dev openssl libsqlite3-dev libssl-dev libffi-dev unzip pciutils net-tools libblas-dev gfortran libblas3 libopenblas-dev# 升级pippip3 install --upgrade pip# 安装pip依赖pip3 install attrs numpy decorator sympy cffi pyyaml pathlib2 psutil protobuf scipy requests# 安装toolkit./Ascend-cann-toolkit_5.1.RC2.alpha002_linux-x86_64.run --install 测试 按照官方指导,下载example工程并编译执行即可。","link":"/2023/07/20/%E6%98%87%E8%85%BE%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9B%BA%E4%BB%B6%E4%B8%8E%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"openEuler","slug":"openEuler","link":"/tags/openEuler/"},{"name":"Ascend","slug":"Ascend","link":"/tags/Ascend/"},{"name":"RPM","slug":"RPM","link":"/tags/RPM/"},{"name":"OpenStack","slug":"OpenStack","link":"/tags/OpenStack/"}],"categories":[],"pages":[{"title":"About","text":"This is the organization from Open Source Development Team. It's used for technology sharing.","link":"/about/index.html"},{"title":"昇腾AI全链路原生支持展示","text":"LLM大模型全流程 CV场景（推理）全流程 预训练 Success DataSet 预训练 大模型(L0) 精调 Success 领域数据 精 调 大模型(L1/L2) 知识引入 Success 细分领域数据 集成 模型+知识库 应用集成 Success 应用 集成 模型应用 预处理 原始图片 二值化图片 裁剪后图片 最终图片 推理(ResNet50) 算子1 算子2 算子3 识别结果 ... const popoverTriggerList = document.querySelectorAll('[data-bs-toggle=\"popover\"]') const popoverList = [...popoverTriggerList].map(popoverTriggerEl => new bootstrap.Popover(popoverTriggerEl))","link":"/ascend/index.html"}]}